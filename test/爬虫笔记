模拟浏览器，抓取数据 爬虫
第一章:
第一节
第二节
第三节  爬虫使用
   1.使用场景分类
      - 通用爬虫
        抓取系统的重要组成部分。抓取的互联网中一整张页面数据。
      - 聚焦爬虫
        是建立在通用爬虫基础之上。抓取的是页面中特定局部内容。
      - 增量式爬虫
        检测网站中数据更新的情况。只会抓取网站中最新更新出来的数据。
    2.爬虫的矛与盾
      - 反爬机制
         门户网站可以通过指定相应的策略或者技术手段防止爬虫程序进行网站数据的爬取。

      -  反反爬策略
      - robots.txt 协议
         君子协定。
         www.taobao.com/robots.txt

第四节：http和https
        - 概念：服务器和客户进行数据交互的一种形式。
     1.常用请求头信息(只介绍在抓取中用到的信息)
       - User-Agent:请求载体的身份标示
       - Connection:请求完毕后，是断开链接还是保持链接。 keepalive or close.

     2.常用响应头信息
       - Content-Type: 服务器端响应回客户端的数据类型（字符串,json...）

     3.https协议
       - 安全的http协议
     4.加密方式
       - 对称密钥加密
       - 非对称密钥加密
       - 证书密钥加密

第二章：requests模块
基于网络请求的模块 urllib模块和requests模块（只讲requests模块）

第一节：requests模块：
    python中原声的网络请求模块，功能强大，简单便捷，高效。
    作用:模拟浏览器发请求。

    如何使用（requests模块的编码流程）：
       - 指定url
       - 发起http或https请求，方式可能是get或post请求。
       - 获取响应数据，
       - 持久化存储响应数据
    环境安装：
       pip install requests

    实战编码：
       - 需求:爬取sogo首页的网站数据。

第二节：requests实战
     需求:
        - 爬取搜狗指定此条对应的搜索结果页面
        - 破解百度翻译
        - 爬取豆瓣电影分类排行榜
        - 爬取肯定记餐厅查询 http://www.kfc.com.cn/kfccda/index.aspx
        - 爬取国家药品监督管理中局中基于中华人民共和国化妆品许可证相关数据


     1.爬取搜狗指定此条对应的搜索结果页面


     作业：